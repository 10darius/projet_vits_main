# COURS MATH√âMATIQUE : VITS (Variational Inference with adversarial learning for end-to-end Text-to-Speech)

## üìö TABLE DES MATI√àRES
1. [Introduction](#1-introduction)
2. [Fondements Math√©matiques](#2-fondements-math√©matiques)
3. [Architecture du Mod√®le](#3-architecture-du-mod√®le)
4. [Formules Cl√©s](#4-formules-cl√©s)
5. [Algorithmes](#5-algorithmes)

---

## 1. INTRODUCTION

VITS est un mod√®le de synth√®se vocale (Text-to-Speech) qui combine :
- **VAE (Variational Autoencoder)** : Mod√©lisation probabiliste
- **GAN (Generative Adversarial Network)** : Apprentissage adversarial
- **Normalizing Flows** : Transformations inversibles

---

## 2. FONDEMENTS MATH√âMATIQUES

### 2.1 Probabilit√©s et Distributions

#### Distribution Gaussienne (Normale)
```
p(x) = (1/‚àö(2œÄœÉ¬≤)) * exp(-(x-Œº)¬≤/(2œÉ¬≤))
```
- **Œº** : moyenne
- **œÉ¬≤** : variance
- **log(œÉ)** : log-variance (utilis√© dans le code pour stabilit√© num√©rique)

#### Divergence de Kullback-Leibler (KL)
Mesure la diff√©rence entre deux distributions p et q :
```
KL(q||p) = ‚à´ q(x) log(q(x)/p(x)) dx
```

Pour deux gaussiennes :
```
KL(N(Œº‚ÇÅ,œÉ‚ÇÅ¬≤) || N(Œº‚ÇÇ,œÉ¬≤)) = log(œÉ‚ÇÇ/œÉ‚ÇÅ) + (œÉ‚ÇÅ¬≤ + (Œº‚ÇÅ-Œº‚ÇÇ)¬≤)/(2œÉ‚ÇÇ¬≤) - 1/2
```

**Dans le code (losses.py, ligne 48-59)** :
```python
def kl_loss(z_p, logs_q, m_p, logs_p, z_mask):
    kl = logs_p - logs_q - 0.5
    kl += 0.5 * ((z_p - m_p)**2) * torch.exp(-2. * logs_p)
    kl = torch.sum(kl * z_mask)
    l = kl / torch.sum(z_mask)
    return l
```

### 2.2 Variational Autoencoder (VAE)

#### Objectif ELBO (Evidence Lower Bound)
```
log p(x) ‚â• E_q[log p(x|z)] - KL(q(z|x) || p(z))
         = ELBO
```

- **p(x|z)** : vraisemblance (likelihood)
- **q(z|x)** : encodeur (posterior approximation)
- **p(z)** : prior (g√©n√©ralement N(0,I))

#### Reparameterization Trick
Pour √©chantillonner z ~ N(Œº, œÉ¬≤) de mani√®re diff√©rentiable :
```
z = Œº + œÉ * Œµ,  o√π Œµ ~ N(0,1)
```

**Dans le code (models.py, ligne 234)** :
```python
z = (m + torch.randn_like(m) * torch.exp(logs)) * x_mask
```

---

## 3. ARCHITECTURE DU MOD√àLE

### 3.1 Encodeur de Texte (TextEncoder)

**R√¥le** : Convertir phon√®mes ‚Üí repr√©sentation latente

#### Embedding
Transformation : indices discrets ‚Üí vecteurs continus
```
e_i = W[i] ‚àà ‚Ñù^d
```
Normalisation : `e_i * ‚àöd` (comme dans Transformer)

**Code (models.py, ligne 145-147)** :
```python
self.emb = nn.Embedding(n_vocab, hidden_channels)
nn.init.normal_(self.emb.weight, 0.0, hidden_channels**-0.5)
x = self.emb(x) * math.sqrt(self.hidden_channels)
```

#### Projection vers Œº et log(œÉ)
```
[Œº, log(œÉ)] = Conv1D(h)
```
- **Œº** : moyenne de la distribution latente
- **log(œÉ)** : log-√©cart-type (pour stabilit√©)

### 3.2 Encodeur Post√©rieur (PosteriorEncoder)

**R√¥le** : Encoder le mel-spectrogramme en repr√©sentation latente

#### Formule
```
z ~ q(z|y) = N(Œº_q, œÉ_q¬≤)
Œº_q, log(œÉ_q) = Encoder(y)
z = Œº_q + œÉ_q * Œµ
```

**Code (models.py, ligne 232-235)** :
```python
stats = self.proj(x) * x_mask
m, logs = torch.split(stats, self.out_channels, dim=1)
z = (m + torch.randn_like(m) * torch.exp(logs)) * x_mask
```

### 3.3 Normalizing Flow (ResidualCouplingBlock)

**Principe** : Transformation inversible pour augmenter l'expressivit√©

#### Coupling Layer (Couche de Couplage)
Divise l'entr√©e en deux parties [x_a, x_b] :
```
y_a = x_a
y_b = x_b * exp(s(x_a)) + t(x_a)
```
- **s(x_a)** : fonction de scale (√©chelle)
- **t(x_a)** : fonction de translation

#### Jacobien et Log-d√©terminant
Pour une transformation y = f(x), le changement de densit√© :
```
p_y(y) = p_x(x) / |det(‚àÇf/‚àÇx)|
log p_y(y) = log p_x(x) - log|det(‚àÇf/‚àÇx)|
```

Pour le coupling layer :
```
log|det(‚àÇf/‚àÇx)| = Œ£ s(x_a)
```

### 3.4 Pr√©dicteur de Dur√©e Stochastique (StochasticDurationPredictor)

**Objectif** : Pr√©dire la dur√©e de chaque phon√®me de mani√®re probabiliste

#### Formulation
```
w ~ p(w|x) o√π w = dur√©es
log p(w|x) = log p(z) - log|det(‚àÇf/‚àÇw)|
```

#### Transformation Log-Flow
```
z‚ÇÄ = log(w)
z = Flow(z‚ÇÄ)
```

**Code (models.py, ligne 68-73)** :
```python
logdet_tot = 0
z0, logdet = self.log_flow(z0, x_mask)
logdet_tot += logdet
z = torch.cat([z0, z1], 1)
for flow in flows:
    z, logdet = flow(z, x_mask, g=x, reverse=reverse)
```

### 3.5 Monotonic Alignment Search (MAS)

**Probl√®me** : Aligner texte et audio sans supervision

#### Formulation
Trouver l'alignement optimal A qui maximise :
```
A* = argmax_A Œ£_t log p(y_t | x_{A(t)})
```

#### Negative Cross-Entropy
```
-H(y, x) = -Œ£ log p(y_t | x_s)
```

**Code (models.py, ligne 461-467)** :
```python
s_p_sq_r = torch.exp(-2 * logs_p)
neg_cent1 = torch.sum(-0.5 * math.log(2 * math.pi) - logs_p, [1], keepdim=True)
neg_cent2 = torch.matmul(-0.5 * (z_p ** 2).transpose(1, 2), s_p_sq_r)
neg_cent3 = torch.matmul(z_p.transpose(1, 2), (m_p * s_p_sq_r))
neg_cent4 = torch.sum(-0.5 * (m_p ** 2) * s_p_sq_r, [1], keepdim=True)
neg_cent = neg_cent1 + neg_cent2 + neg_cent3 + neg_cent4
attn = monotonic_align.maximum_path(neg_cent, attn_mask.squeeze(1))
```

---

## 4. FORMULES CL√âS

### 4.1 Fonction de Perte Totale

```
L_total = L_recon + L_kl + L_dur + L_adv + L_fm
```

#### 4.1.1 Perte de Reconstruction (L_recon)
```
L_recon = ||y - ≈∑||¬≤
```
Mesure la diff√©rence entre audio r√©el et g√©n√©r√©

#### 4.1.2 Perte KL (L_kl)
```
L_kl = KL(q(z|y) || p(z|x))
```
**Code (losses.py)** :
```python
kl = logs_p - logs_q - 0.5
kl += 0.5 * ((z_p - m_p)**2) * torch.exp(-2. * logs_p)
```

#### 4.1.3 Perte de Dur√©e (L_dur)
Pour le pr√©dicteur stochastique :
```
L_dur = -log p(w|x)
```

Pour le pr√©dicteur d√©terministe :
```
L_dur = MSE(log(w), log(≈µ))
```

**Code (models.py, ligne 476-481)** :
```python
if self.use_sdp:
    l_length = self.dp(x, x_mask, w, g=g)
    l_length = l_length / torch.sum(x_mask)
else:
    logw_ = torch.log(w + 1e-6) * x_mask
    l_length = torch.sum((logw - logw_)**2, [1,2]) / torch.sum(x_mask)
```

#### 4.1.4 Perte Adversariale (L_adv)

**Discriminateur** :
```
L_D = E[(1 - D(y_real))¬≤] + E[D(y_fake)¬≤]
```

**G√©n√©rateur** :
```
L_G = E[(1 - D(y_fake))¬≤]
```

**Code (losses.py, ligne 18-30)** :
```python
def discriminator_loss(disc_real_outputs, disc_generated_outputs):
    for dr, dg in zip(disc_real_outputs, disc_generated_outputs):
        r_loss = torch.mean((1-dr)**2)
        g_loss = torch.mean(dg**2)
        loss += (r_loss + g_loss)
```

#### 4.1.5 Perte de Feature Matching (L_fm)
```
L_fm = Œ£ ||œÜ_i(y_real) - œÜ_i(y_fake)||‚ÇÅ
```
o√π œÜ_i sont les features interm√©diaires du discriminateur

**Code (losses.py, ligne 7-15)** :
```python
def feature_loss(fmap_r, fmap_g):
    loss = 0
    for dr, dg in zip(fmap_r, fmap_g):
        for rl, gl in zip(dr, dg):
            loss += torch.mean(torch.abs(rl - gl))
    return loss * 2
```

### 4.2 Rational Quadratic Spline (RQS)

Transformation non-lin√©aire pour les flows :

#### Forward
```
y = h(x) = y_k + (y_{k+1} - y_k) * [s_k * (x - x_k)¬≤ + d_k * (x - x_k) * (x_{k+1} - x)] / 
           [s_k * (x - x_k) + d_k * (x_{k+1} - x) + d_{k+1} * (x - x_k)]
```

#### Inverse
R√©solution d'√©quation quadratique :
```
a * Œæ¬≤ + b * Œæ + c = 0
Œæ = (2c) / (-b - ‚àö(b¬≤ - 4ac))
```

**Code (transforms.py, ligne 155-165)** :
```python
a = (((inputs - input_cumheights) * (input_derivatives + input_derivatives_plus_one - 2 * input_delta)
      + input_heights * (input_delta - input_derivatives)))
b = (input_heights * input_derivatives
     - (inputs - input_cumheights) * (input_derivatives + input_derivatives_plus_one - 2 * input_delta))
c = - input_delta * (inputs - input_cumheights)
discriminant = b.pow(2) - 4 * a * c
root = (2 * c) / (-b - torch.sqrt(discriminant))
```

---

## 5. ALGORITHMES

### 5.1 Algorithme d'Entra√Ænement

```
Pour chaque batch (x, y) :
    1. Encoder le texte : Œº_p, œÉ_p = TextEncoder(x)
    2. Encoder l'audio : z, Œº_q, œÉ_q = PosteriorEncoder(y)
    3. Flow : z_p = Flow(z)
    4. Alignement : A = MonotonicAlign(z_p, Œº_p, œÉ_p)
    5. Dur√©e : L_dur = DurationPredictor(x, A)
    6. G√©n√©ration : ≈∑ = Generator(z)
    7. Discrimination : D_real, D_fake = Discriminator(y, ≈∑)
    
    8. Calculer les pertes :
       L_kl = KL(q(z|y) || p(z|x))
       L_dur = -log p(w|x)
       L_adv = (1 - D_fake)¬≤
       L_fm = ||œÜ(y) - œÜ(≈∑)||
    
    9. Backpropagation et mise √† jour
```

### 5.2 Algorithme d'Inf√©rence

```
Entr√©e : texte x
1. Encoder : Œº_p, œÉ_p = TextEncoder(x)
2. Pr√©dire dur√©e : w = DurationPredictor(x)
3. Expansion : Œº_p', œÉ_p' = Expand(Œº_p, œÉ_p, w)
4. √âchantillonner : z_p ~ N(Œº_p', œÉ_p')
5. Flow inverse : z = Flow‚Åª¬π(z_p)
6. G√©n√©rer : y = Generator(z)
Sortie : audio y
```

---

## 6. CONCEPTS AVANC√âS

### 6.1 Attention Multi-T√™tes

Formule g√©n√©rale :
```
Attention(Q, K, V) = softmax(QK^T / ‚àöd_k) V
MultiHead(Q, K, V) = Concat(head‚ÇÅ, ..., head_h) W^O
o√π head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)
```

### 6.2 Convolution avec Dilatation

```
y[i] = Œ£_k w[k] * x[i + k*d]
```
o√π d = taux de dilatation

### 6.3 Weight Normalization

```
w = g * v / ||v||
```
- **v** : vecteur de poids
- **g** : scalaire appris
- Stabilise l'entra√Ænement

---

## 7. EXERCICES PRATIQUES

### Exercice 1 : Calculer la KL divergence
Donn√©es : Œº‚ÇÅ=0, œÉ‚ÇÅ=1, Œº‚ÇÇ=2, œÉ‚ÇÇ=0.5
```
KL = log(0.5/1) + (1 + 4)/(2*0.25) - 0.5
   = -0.693 + 10 - 0.5
   = 8.807
```

### Exercice 2 : Reparameterization
√âchantillonner z ~ N(3, 4) :
```
Œµ ~ N(0,1)  # ex: Œµ = 0.5
z = 3 + 2*0.5 = 4
```

### Exercice 3 : Log-d√©terminant du Coupling Layer
Si s(x_a) = [1, 2, 3] :
```
log|det(J)| = 1 + 2 + 3 = 6
```

---

## 8. R√âF√âRENCES MATH√âMATIQUES

### Notations
- **‚äô** : produit √©l√©ment par √©l√©ment (Hadamard)
- **‚äï** : concat√©nation
- **‚àá** : gradient
- **‚àÇ** : d√©riv√©e partielle
- **E[¬∑]** : esp√©rance
- **N(Œº,œÉ¬≤)** : distribution normale

### Constantes
- **œÄ** ‚âà 3.14159
- **e** ‚âà 2.71828
- **log** : logarithme naturel (base e)

---

## CONCLUSION

VITS combine √©l√©gamment :
1. **VAE** pour la mod√©lisation probabiliste
2. **Flows** pour l'expressivit√©
3. **GAN** pour la qualit√© audio
4. **MAS** pour l'alignement automatique

Les math√©matiques sous-jacentes reposent sur :
- Th√©orie des probabilit√©s
- Optimisation
- Transformations diff√©rentiables
- Apprentissage adversarial
